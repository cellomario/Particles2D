#!/bin/bash
#SBATCH --nodes=1             # -N nodes 
#SBATCH --ntasks-per-node=1   # MPI tasks/node (max 128)
#SBATCH --cpus-per-task=24     # OpenMP threads/task
#SBATCH --gres=gpu:0          # 1 gpu per node (max 4)
#SBATCH --time=00:10:00        # max 24:00:00
#SBATCH --mem=14GB            # memory/node (max 246GB)
#SBATCH -A tra23_PoliMI_e
#SBATCH -p g100_usr_interactive
#SBATCH --job-name=particles2023_c             # job_name
#SBATCH --error=errjobfile-%J.err    # stderr file
#SBATCH --output=outjobfile-%J.out   # stdout file
echo "Job started at " `date`
rm *.ppm *.jpg *.dmp *.sta
module purge
module load autoload
module load intel/oneapi-2022--binary
source /cineca/prod/opt/compilers/intel/oneapi-2022/binary/setvars.sh
icc -g -qopenmp -O2 -parallel-source-info=2 particles2023.c -o particles2023_c.exe
export OMP_NUM_THREADS=4
vtune -collect hpc-performance ./particles2023_c.exe
wait
echo "Job finished at " `date`
exit
